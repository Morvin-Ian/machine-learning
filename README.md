# Machine Learning Learning Path

A comprehensive, structured curriculum for learning machine learning from basics to advanced theory.

## ğŸ“š Project Structure

This repository is organized into a clear learning progression with three main sections:

### [01-Supervised Learning](./01-supervised-learning) â€” **Start Here!**
Algorithms that learn from labeled training data to make predictions. This is the best starting point.

- **[Linear Regression](./01-supervised-learning/linear-regression/notes.md)** - Predicting continuous values
- **[Logistic Regression](./01-supervised-learning/logistic-regression/notes.md)** - Binary and multi-class classification
- **[Classification](./01-supervised-learning/classification/notes.md)** - Evaluation metrics and thresholds

### [02-Unsupervised Learning](./02-unsupervised-learning)
Algorithms that discover patterns in unlabeled data.

- **[Clustering](./02-unsupervised-learning/clustering/notes.md)** - K-Means, Hierarchical, DBSCAN
- **[Dimensionality Reduction](./02-unsupervised-learning/dimensionality-reduction/notes.md)** - PCA, t-SNE
- **[Anomaly Detection](./02-unsupervised-learning/anomaly-detection/notes.md)** - Isolation Forest, One-Class SVM

### [03-Deep Dives](./03-deep-dives)
Advanced mathematical concepts and in-depth explanations of core algorithms.

- **[Gradient Descent](./03-deep-dives/gradient-descent/notes.md)** - The optimization algorithm that powers ML
  - Intuitive explanation with visual analogies
  - Mathematical derivation and update rules
  - Variants: Batch, Stochastic, Mini-batch
  - Advanced optimizers: Momentum, Adam

## ğŸš€ Getting Started

### Prerequisites

- Python 3.12+
- pip or uv package manager

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd machine-learning

# Install dependencies
pip install -r requirements.txt
# or with uv:
uv sync
```

### Recommended Learning Order

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. SUPERVISED LEARNING (Start Here!)  â”‚
â”‚     Linear Regression â†’ Logistic       â”‚
â”‚     Regression â†’ Classification         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. UNSUPERVISED LEARNING              â”‚
â”‚     Clustering â†’ Dimensionality        â”‚
â”‚     Reduction â†’ Anomaly Detection      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. DEEP DIVES (Reference as needed)   â”‚
â”‚     Gradient Descent (optimization)    â”‚
â”‚     [More topics coming...]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Start with**: [01-supervised-learning](./01-supervised-learning)
   - Begin with linear regression for regression basics
   - Progress to logistic regression for classification
   - Learn classification metrics and evaluation

2. **Then explore**: [02-unsupervised-learning](./02-unsupervised-learning)
   - Start with clustering (K-Means)
   - Learn dimensionality reduction (PCA)
   - Explore anomaly detection

3. **Reference as needed**: [03-deep-dives](./03-deep-dives)
   - Deep dive into gradient descent when you want to understand optimization
   - Use as reference when you encounter these concepts in practice

## ğŸ“‹ Dependencies

See `pyproject.toml` for full list. Key packages include:

- **numpy** - Numerical computing
- **pandas** - Data manipulation
- **matplotlib & plotly** - Data visualization
- **scikit-learn** - Machine learning algorithms
- **tensorflow & keras** - Deep learning

## ğŸ“– How to Use This Repository

Each section contains:
- **notes.md** - Detailed explanations, theory, and examples
- **code files** - Practical implementations
- **README.md** - Section-specific guidance and prerequisites

Start with the notes to understand the theory, then explore the code implementations.

## ğŸ”— File Structure Overview

```
machine-learning/
â”œâ”€â”€ README.md                           (This file)
â”œâ”€â”€ pyproject.toml                      (Project configuration)
â”‚
â”œâ”€â”€ 01-supervised-learning/             â† START HERE
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ linear-regression/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â””â”€â”€ notes.md
â”‚   â”œâ”€â”€ logistic-regression/
â”‚   â”‚   â””â”€â”€ notes.md
â”‚   â””â”€â”€ classification/
â”‚       â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 02-unsupervised-learning/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ notes.md                        (Overview)
â”‚   â”œâ”€â”€ clustering/
â”‚   â”‚   â””â”€â”€ notes.md
â”‚   â”œâ”€â”€ dimensionality-reduction/
â”‚   â”‚   â””â”€â”€ notes.md
â”‚   â””â”€â”€ anomaly-detection/
â”‚       â””â”€â”€ notes.md
â”‚
â””â”€â”€ 03-deep-dives/                      â† Reference material
    â”œâ”€â”€ README.md
    â””â”€â”€ gradient-descent/
        â””â”€â”€ notes.md                    (Comprehensive GD guide)
```

## ğŸ’¡ Tips for Success

1. **Follow the order** - Start with supervised learning, the most intuitive introduction
2. **Understand the theory** - Read the notes before running code
3. **Experiment** - Modify code examples and explore variations
4. **Use deep dives** - Reference the advanced topics when you want to understand "how it works"
5. **Practice** - Implement algorithms from scratch when possible

## ğŸ¤ Contributing

Feel free to improve this learning path! Suggestions are welcome.

## ğŸ“ License

[Add your license information here]

---

**Happy Learning!** ğŸ“

Start with [01-supervised-learning/linear-regression](./01-supervised-learning/linear-regression/notes.md) and follow the learning path outlined above.
